{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F37NU3ZBLsBQ",
        "outputId": "ed1dde17-3092-4a80-e8b6-86c94fc99915"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\r0% [Working]\r            \rHit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "\r0% [Connecting to archive.ubuntu.com (185.125.190.39)] [Connected to cloud.r-pr\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "\r                                                                               \rHit:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "\r                                                                               \rHit:4 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "\r                                                                               \rHit:5 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "\r0% [Waiting for headers] [Connected to cloud.r-project.org (13.227.219.19)] [Co\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rHit:6 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Waiting for headers] [Conn\r                                                                               \rHit:7 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "\r0% [1 InRelease gpgv 88.7 kB] [Waiting for headers] [Connecting to ppa.launchpa\r                                                                               \rHit:8 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:9 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Ign:10 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:11 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Reading package lists... Done\n",
            "^C\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!apt-get update\n",
        "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
        "!wget -q http://archive.apache.org/dist/spark/spark-3.1.1/spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!tar xf spark-3.1.1-bin-hadoop3.2.tgz\n",
        "!pip install -q findspark"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-8-openjdk-amd64\"\n",
        "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.1.1-bin-hadoop3.2\""
      ],
      "metadata": {
        "id": "vxg9YuEmMGiw"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import findspark\n",
        "findspark.init()\n",
        "from pyspark.sql import SparkSession\n",
        "spark = SparkSession.builder.master(\"local\").appName(\"Spark\").getOrCreate()\n",
        "spark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "pzWDihH5NN7L",
        "outputId": "f683938e-eddc-4da9-9edc-116aaaf3af10"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pyspark.sql.session.SparkSession at 0x7f4260af7e90>"
            ],
            "text/html": [
              "\n",
              "            <div>\n",
              "                <p><b>SparkSession - in-memory</b></p>\n",
              "                \n",
              "        <div>\n",
              "            <p><b>SparkContext</b></p>\n",
              "\n",
              "            <p><a href=\"http://173619cecffb:4040\">Spark UI</a></p>\n",
              "\n",
              "            <dl>\n",
              "              <dt>Version</dt>\n",
              "                <dd><code>v3.1.1</code></dd>\n",
              "              <dt>Master</dt>\n",
              "                <dd><code>local</code></dd>\n",
              "              <dt>AppName</dt>\n",
              "                <dd><code>Spark</code></dd>\n",
              "            </dl>\n",
              "        </div>\n",
              "        \n",
              "            </div>\n",
              "        "
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import functions\n",
        "print(dir(functions))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMqU9iHONRtU",
        "outputId": "85ce8b56-dac2-4f85-b339-c64623a1c54c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Column', 'DataFrame', 'DataType', 'PandasUDFType', 'PythonEvalType', 'SparkContext', 'StringType', 'UserDefinedFunction', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '_create_column_from_literal', '_create_lambda', '_create_udf', '_get_get_jvm_function', '_get_lambda_parameters', '_invoke_binary_math_function', '_invoke_function', '_invoke_function_over_column', '_invoke_higher_order_function', '_options_to_str', '_test', '_to_java_column', '_to_seq', '_unresolved_named_lambda_variable', 'abs', 'acos', 'acosh', 'add_months', 'aggregate', 'approxCountDistinct', 'approx_count_distinct', 'array', 'array_contains', 'array_distinct', 'array_except', 'array_intersect', 'array_join', 'array_max', 'array_min', 'array_position', 'array_remove', 'array_repeat', 'array_sort', 'array_union', 'arrays_overlap', 'arrays_zip', 'asc', 'asc_nulls_first', 'asc_nulls_last', 'ascii', 'asin', 'asinh', 'assert_true', 'atan', 'atan2', 'atanh', 'avg', 'base64', 'bin', 'bitwiseNOT', 'broadcast', 'bround', 'bucket', 'cbrt', 'ceil', 'coalesce', 'col', 'collect_list', 'collect_set', 'column', 'concat', 'concat_ws', 'conv', 'corr', 'cos', 'cosh', 'count', 'countDistinct', 'covar_pop', 'covar_samp', 'crc32', 'create_map', 'cume_dist', 'current_date', 'current_timestamp', 'date_add', 'date_format', 'date_sub', 'date_trunc', 'datediff', 'dayofmonth', 'dayofweek', 'dayofyear', 'days', 'decode', 'degrees', 'dense_rank', 'desc', 'desc_nulls_first', 'desc_nulls_last', 'element_at', 'encode', 'exists', 'exp', 'explode', 'explode_outer', 'expm1', 'expr', 'factorial', 'filter', 'first', 'flatten', 'floor', 'forall', 'format_number', 'format_string', 'from_csv', 'from_json', 'from_unixtime', 'from_utc_timestamp', 'functools', 'get_json_object', 'greatest', 'grouping', 'grouping_id', 'hash', 'hex', 'hour', 'hours', 'hypot', 'initcap', 'input_file_name', 'instr', 'isnan', 'isnull', 'json_tuple', 'kurtosis', 'lag', 'last', 'last_day', 'lead', 'least', 'length', 'levenshtein', 'lit', 'locate', 'log', 'log10', 'log1p', 'log2', 'lower', 'lpad', 'ltrim', 'map_concat', 'map_entries', 'map_filter', 'map_from_arrays', 'map_from_entries', 'map_keys', 'map_values', 'map_zip_with', 'max', 'md5', 'mean', 'min', 'minute', 'monotonically_increasing_id', 'month', 'months', 'months_between', 'nanvl', 'next_day', 'nth_value', 'ntile', 'overlay', 'pandas_udf', 'percent_rank', 'percentile_approx', 'posexplode', 'posexplode_outer', 'pow', 'quarter', 'radians', 'raise_error', 'rand', 'randn', 'rank', 'regexp_extract', 'regexp_replace', 'repeat', 'reverse', 'rint', 'round', 'row_number', 'rpad', 'rtrim', 'schema_of_csv', 'schema_of_json', 'second', 'sequence', 'sha1', 'sha2', 'shiftLeft', 'shiftRight', 'shiftRightUnsigned', 'shuffle', 'signum', 'sin', 'since', 'sinh', 'size', 'skewness', 'slice', 'sort_array', 'soundex', 'spark_partition_id', 'split', 'sqrt', 'stddev', 'stddev_pop', 'stddev_samp', 'struct', 'substring', 'substring_index', 'sum', 'sumDistinct', 'sys', 'tan', 'tanh', 'timestamp_seconds', 'toDegrees', 'toRadians', 'to_csv', 'to_date', 'to_json', 'to_str', 'to_timestamp', 'to_utc_timestamp', 'transform', 'transform_keys', 'transform_values', 'translate', 'trim', 'trunc', 'udf', 'unbase64', 'unhex', 'unix_timestamp', 'upper', 'var_pop', 'var_samp', 'variance', 'warnings', 'weekofyear', 'when', 'window', 'xxhash64', 'year', 'years', 'zip_with']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lit,lower, upper,concat,substring\n",
        "\n",
        "emp_info = spark.read.csv('Employee_info.csv', header=True, sep=\",\", inferSchema=True)\n",
        "emp_info.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeQ86_XtNYbo",
        "outputId": "ed6ba8ee-af06-468d-d805-997aa612a041"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+-----------+----+-------------+\n",
            "|Emp_id|    Name|Emp_dept_id|Days|working_hours|\n",
            "+------+--------+-----------+----+-------------+\n",
            "|     1|   Smith|      45645|   8|            8|\n",
            "|     2|    Rose|      46887|   9|            6|\n",
            "|     3| Juliana|      45645|   7|            8|\n",
            "|     4|Anjelina|      46578|   6|            6|\n",
            "|     5|  Robert|      47863|   1|            8|\n",
            "|     6|   Bruce|      43879|   2|            8|\n",
            "|     7|   Brown|      48378|   3|            5|\n",
            "|     8|    Bean|      45789|   1|            8|\n",
            "|     9|    Nike|      42389|   4|            6|\n",
            "|    10|    Nate|      41868|   5|            6|\n",
            "+------+--------+-----------+----+-------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql.functions import lit,lower, upper,concat,substring\n",
        "\n",
        "emp = spark.read.csv('employee.csv', header=True, sep=\",\", inferSchema=True)\n",
        "emp.show(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gZ5Cs7fRXMat",
        "outputId": "11a00415-fec2-4c00-a912-9950f94187dc"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---+------+----------+------+-----+\n",
            "| ID|Salary|Department|  city|state|\n",
            "+---+------+----------+------+-----+\n",
            "|  1| 45000|        IT|   SFO|   CA|\n",
            "|  2| 50000|        IT|Jersey|   MA|\n",
            "|  3| 65000|       IOT|    NY|   DA|\n",
            "|  4| 45000|        CS|    MC|   NJ|\n",
            "|  5| 35000|        CS|   SAN|   DE|\n",
            "|  6| 50000|       EEE|Jersey|   DE|\n",
            "|  7| 30000|       EEE|JORGEA|   JD|\n",
            "|  8| 40000|        SE|Newark|   PO|\n",
            "|  9| 35000|        SE| TOKYO|   TA|\n",
            "| 10| 40000|        CS|Newark|   BD|\n",
            "+---+------+----------+------+-----+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emp_info.join(emp, emp_info.Emp_id == emp.ID, \"cross\").select(emp_info[\"Emp_id\"], emp_info[\"Name\"], emp[\"Salary\"]).show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N3NGihrjXg6v",
        "outputId": "58ac1cef-2769-4bdc-d3c6-c1a6a7f558aa"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+------+\n",
            "|Emp_id|    Name|Salary|\n",
            "+------+--------+------+\n",
            "|     1|   Smith| 45000|\n",
            "|     2|    Rose| 50000|\n",
            "|     3| Juliana| 65000|\n",
            "|     4|Anjelina| 45000|\n",
            "|     5|  Robert| 35000|\n",
            "|     6|   Bruce| 50000|\n",
            "|     7|   Brown| 30000|\n",
            "|     8|    Bean| 40000|\n",
            "|     9|    Nike| 35000|\n",
            "|    10|    Nate| 40000|\n",
            "+------+--------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emp_info.join(emp, emp_info.Emp_id == emp.ID, \"outer\").select(emp_info[\"Emp_id\"], emp_info[\"Name\"], emp[\"Salary\"]).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCtfqAtNY7Pm",
        "outputId": "3799d0e3-2c9e-47f5-ee61-88e6939cab50"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+------+\n",
            "|Emp_id|    Name|Salary|\n",
            "+------+--------+------+\n",
            "|     1|   Smith| 45000|\n",
            "|     6|   Bruce| 50000|\n",
            "|     3| Juliana| 65000|\n",
            "|     5|  Robert| 35000|\n",
            "|     9|    Nike| 35000|\n",
            "|     4|Anjelina| 45000|\n",
            "|     8|    Bean| 40000|\n",
            "|     7|   Brown| 30000|\n",
            "|    10|    Nate| 40000|\n",
            "|     2|    Rose| 50000|\n",
            "+------+--------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emp_info.join(emp, emp_info.Emp_id == emp.ID, \"leftouter\").select(emp_info[\"Emp_id\"], emp_info[\"Name\"], emp[\"Salary\"]).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z2DpOCNbYYI8",
        "outputId": "8fae8043-92c4-4baf-d587-a147f27db7ae"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+------+\n",
            "|Emp_id|    Name|Salary|\n",
            "+------+--------+------+\n",
            "|     1|   Smith| 45000|\n",
            "|     2|    Rose| 50000|\n",
            "|     3| Juliana| 65000|\n",
            "|     4|Anjelina| 45000|\n",
            "|     5|  Robert| 35000|\n",
            "|     6|   Bruce| 50000|\n",
            "|     7|   Brown| 30000|\n",
            "|     8|    Bean| 40000|\n",
            "|     9|    Nike| 35000|\n",
            "|    10|    Nate| 40000|\n",
            "+------+--------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emp_info.join(emp, emp_info.Emp_id == emp.ID, \"rightouter\").select(emp_info[\"Emp_id\"], emp_info[\"Name\"], emp[\"Salary\"]).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlctrDHnY6ua",
        "outputId": "d87bbfcb-eb2e-44b9-e179-8ca8344a84d8"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+------+\n",
            "|Emp_id|    Name|Salary|\n",
            "+------+--------+------+\n",
            "|     1|   Smith| 45000|\n",
            "|     2|    Rose| 50000|\n",
            "|     3| Juliana| 65000|\n",
            "|     4|Anjelina| 45000|\n",
            "|     5|  Robert| 35000|\n",
            "|     6|   Bruce| 50000|\n",
            "|     7|   Brown| 30000|\n",
            "|     8|    Bean| 40000|\n",
            "|     9|    Nike| 35000|\n",
            "|    10|    Nate| 40000|\n",
            "+------+--------+------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emp_info.join(emp, emp_info.Emp_id == emp.ID, \"fullouter\").select(emp_info[\"Emp_id\"], emp_info[\"Name\"], emp[\"Salary\"]).show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kyJH77cMY3Tx",
        "outputId": "3ce00224-ac1a-4afc-f55d-99f95848da57"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+--------+------+\n",
            "|Emp_id|    Name|Salary|\n",
            "+------+--------+------+\n",
            "|     1|   Smith| 45000|\n",
            "|     6|   Bruce| 50000|\n",
            "|     3| Juliana| 65000|\n",
            "|     5|  Robert| 35000|\n",
            "|     9|    Nike| 35000|\n",
            "|     4|Anjelina| 45000|\n",
            "|     8|    Bean| 40000|\n",
            "|     7|   Brown| 30000|\n",
            "|    10|    Nate| 40000|\n",
            "|     2|    Rose| 50000|\n",
            "+------+--------+------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}